#!/usr/bin/env python3
"""
æµ‹è¯•å®Œæ•´ç‰ˆ data_vectorizer å·¥å…·åŠŸèƒ½
"""

import asyncio
import json
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from mcp_tools.data_vectorizer import vectorize_tapd_data, search_tapd_data, get_vector_db_info

async def test_data_vectorizer():
    """æµ‹è¯•å®Œæ•´ç‰ˆå‘é‡åŒ–å·¥å…·"""
    print("=== æµ‹è¯•å®Œæ•´ç‰ˆ data_vectorizer å·¥å…· ===\n")
    
    # 1. æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    data_file = "local_data/msg_from_fetcher.json"
    if not os.path.exists(data_file):
        print(f"âš ï¸  æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        print("è¯·å…ˆè¿è¡Œ tapd_data_fetcher.py è·å–æ•°æ®")
        return False
    
    print(f"âœ… æ•°æ®æ–‡ä»¶å­˜åœ¨: {data_file}\n")
    
    # 2. æµ‹è¯•æ•°æ®åº“ä¿¡æ¯è·å–
    print("ğŸ“Š æµ‹è¯•æ•°æ®åº“ä¿¡æ¯è·å–...")
    try:
        db_info = await get_vector_db_info()
        print(f"æ•°æ®åº“çŠ¶æ€: {db_info['status']}")
        print(f"ä¿¡æ¯: {db_info['message']}")
        if db_info['status'] == 'not_found':
            print("éœ€è¦å…ˆè¿›è¡Œå‘é‡åŒ–\n")
        else:
            print(f"ç»Ÿè®¡ä¿¡æ¯: {json.dumps(db_info.get('stats', {}), ensure_ascii=False, indent=2)}\n")
    except Exception as e:
        print(f"âŒ è·å–æ•°æ®åº“ä¿¡æ¯å¤±è´¥: {e}\n")
    
    # 3. æµ‹è¯•å‘é‡åŒ–åŠŸèƒ½
    print("ğŸ”„ æµ‹è¯•å‘é‡åŒ–åŠŸèƒ½...")
    try:
        result = await vectorize_tapd_data(chunk_size=5)  # ä½¿ç”¨è¾ƒå°çš„åˆ†ç‰‡æµ‹è¯•
        print(f"å‘é‡åŒ–çŠ¶æ€: {result['status']}")
        print(f"ä¿¡æ¯: {result['message']}")
        if result['status'] == 'success':
            stats = result.get('stats', {})
            print(f"ç»Ÿè®¡ä¿¡æ¯: {json.dumps(stats, ensure_ascii=False, indent=2)}")
        print()
    except Exception as e:
        print(f"âŒ å‘é‡åŒ–å¤±è´¥: {e}\n")
        return False
    
    # 4. æµ‹è¯•æœç´¢åŠŸèƒ½
    print("ğŸ” æµ‹è¯•æœç´¢åŠŸèƒ½...")
    test_queries = [
        "ç™»å½•åŠŸèƒ½ç›¸å…³çš„éœ€æ±‚",
        "é«˜ä¼˜å…ˆçº§çš„ç¼ºé™·",
        "ç”¨æˆ·ç•Œé¢é—®é¢˜"
    ]
    
    for query in test_queries:
        try:
            print(f"\næŸ¥è¯¢: {query}")
            result = await search_tapd_data(query, top_k=3)
            print(f"æœç´¢çŠ¶æ€: {result['status']}")
            if result['status'] == 'success':
                results = result.get('results', [])
                print(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœ")
                for i, item in enumerate(results[:2], 1):  # åªæ˜¾ç¤ºå‰2ä¸ªç»“æœ
                    print(f"  ç»“æœ {i}: ç›¸å…³åº¦ {item['relevance_score']:.3f}")
                    chunk_info = item.get('chunk_info', {})
                    print(f"    ç±»å‹: {chunk_info.get('item_type')}, æ¡ç›®æ•°: {chunk_info.get('item_count')}")
            else:
                print(f"æœç´¢å¤±è´¥: {result['message']}")
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
    
    print("\n=== å®Œæ•´ç‰ˆ data_vectorizer æµ‹è¯•å®Œæˆ ===")
    return True

if __name__ == "__main__":
    success = asyncio.run(test_data_vectorizer())
    if success:
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å®Œæ•´ç‰ˆå‘é‡åŒ–å·¥å…·å·¥ä½œæ­£å¸¸ã€‚")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œæ•°æ®ã€‚")
