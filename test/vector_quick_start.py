#!/usr/bin/env python3
"""
TAPDå‘é‡åŒ–åŠŸèƒ½å¿«é€Ÿå¯åŠ¨è„šæœ¬
ç”¨äºå¿«é€Ÿåˆå§‹åŒ–å’Œæµ‹è¯•å‘é‡åŒ–åŠŸèƒ½
"""

import asyncio
import sys
import os

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥æ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from mcp_tools.data_vectorizer import vectorize_tapd_data, search_tapd_data, get_vector_db_info

async def quick_start():
    """å¿«é€Ÿå¯åŠ¨å‘é‡åŒ–åŠŸèƒ½"""
    print("ğŸš€ TAPDå‘é‡åŒ–åŠŸèƒ½å¿«é€Ÿå¯åŠ¨")
    print("=" * 50)
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    data_file = "local_data/msg_from_fetcher.json"
    if not os.path.exists(data_file):
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ {data_file}")
        print("ğŸ“‹ è¯·å…ˆè¿è¡Œ TAPD æ•°æ®è·å–åŠŸèƒ½")
        return
    
    print("âœ… æ•°æ®æ–‡ä»¶æ£€æŸ¥é€šè¿‡")
    
    # æ£€æŸ¥å‘é‡æ•°æ®åº“çŠ¶æ€
    print("\nğŸ” æ£€æŸ¥å‘é‡æ•°æ®åº“çŠ¶æ€...")
    db_info = await get_vector_db_info()
    
    if db_info['status'] == 'not_found':
        print("ğŸ“¦ å‘é‡æ•°æ®åº“ä¸å­˜åœ¨ï¼Œå¼€å§‹åˆå§‹åŒ–...")
        
        # æ‰§è¡Œå‘é‡åŒ–
        result = await vectorize_tapd_data(chunk_size=10)
        if result['status'] == 'success':
            print("âœ… å‘é‡åŒ–å®Œæˆ!")
            stats = result['stats']
            print(f"   â€¢ æ€»åˆ†ç‰‡æ•°: {stats['total_chunks']}")
            print(f"   â€¢ æ€»æ¡ç›®æ•°: {stats['total_items']}")
            print(f"   â€¢ å‘é‡ç»´åº¦: {stats['vector_dimension']}")
        else:
            print(f"âŒ å‘é‡åŒ–å¤±è´¥: {result['message']}")
            return
    else:
        print("âœ… å‘é‡æ•°æ®åº“å·²å°±ç»ª")
        if db_info['status'] == 'ready':
            stats = db_info['stats']
            print(f"   â€¢ æ€»åˆ†ç‰‡æ•°: {stats['total_chunks']}")
            print(f"   â€¢ æ€»æ¡ç›®æ•°: {stats['total_items']}")
    
    # æ¼”ç¤ºæœç´¢åŠŸèƒ½
    print("\nğŸ” æ¼”ç¤ºæœç´¢åŠŸèƒ½...")
    
    demo_queries = [
        "è®¢å•ç›¸å…³åŠŸèƒ½",
        "é¡µé¢å¼‚å¸¸ç¼ºé™·", 
        "å•†å“è¯„ä»·"
    ]
    
    for query in demo_queries:
        print(f"\nğŸ” æœç´¢: '{query}'")
        search_result = await search_tapd_data(query, 2)
        
        if search_result['status'] == 'success':
            results = search_result['results']
            print(f"   æ‰¾åˆ° {len(results)} ä¸ªç»“æœ:")
            
            for i, result in enumerate(results, 1):
                score = result['relevance_score']
                chunk_info = result['chunk_info']
                chunk_type = chunk_info['item_type']
                items = result['items']
                
                if items:
                    title = items[0].get('name') or items[0].get('title', 'æœªçŸ¥')
                    print(f"   {i}. [{chunk_type}] {title} (ç›¸å…³åº¦: {score:.3f})")
                else:
                    print(f"   {i}. [{chunk_type}] (ç›¸å…³åº¦: {score:.3f})")
        else:
            print(f"   âŒ æœç´¢å¤±è´¥: {search_result['message']}")
    
    print("\n" + "=" * 50)
    print("ğŸ‰ å¿«é€Ÿå¯åŠ¨å®Œæˆ!")
    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("   1. åœ¨ Claude Desktop ä¸­æµ‹è¯• MCP å·¥å…·:")
    print("      â€¢ vectorize_data - å‘é‡åŒ–æ•°æ®")
    print("      â€¢ search_data - æ™ºèƒ½æœç´¢")
    print("      â€¢ get_vector_info - è·å–æ•°æ®åº“ä¿¡æ¯")
    print("\n   2. æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£:")
    print("      knowledge_documents\\TAPDæ•°æ®å‘é‡åŒ–åŠŸèƒ½ä½¿ç”¨æ‰‹å†Œ.md")

if __name__ == "__main__":
    asyncio.run(quick_start())
